{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # NumPy: For numerical and array operations.\n",
    "import pandas as pd  # Pandas: For data manipulation and analysis.\n",
    "import matplotlib.pyplot as plt  # Matplotlib: For creating various types of plots and charts.\n",
    "import seaborn as sns  # Seaborn: For making data visualizations more attractive and informative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_visit = pd.read_csv(\"data/october-dm-site-visit-3-23.csv\")\n",
    "form_submit1 = pd.read_csv(\"data/form-submissions-export---V1.csv\").drop([4, 5])\n",
    "form_submit2 = pd.read_csv(\"data/form-submissions-export---V2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify which drop they are from\n",
    "\n",
    "- octoberfreetrial - scanned for the first time in drop 1\n",
    "- octoberfreetrial2 - scanned for the first time in drop 1 (prospects who will receive drop 2 )\n",
    "- octoberfreetrial3 - scanned drop 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize the 'drop' column\n",
    "def categorize_drop(row):\n",
    "    if \"octoberfreetrial3\" in row:\n",
    "        return \"drop2\"\n",
    "    elif \"octoberfreetrial2\" in row:  # Corrected typo here\n",
    "        return \"drop1-prospect\"\n",
    "    elif \"octoberfreetrial\" in row:\n",
    "        return \"drop1\"\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "# Apply the function to create the 'drop' column\n",
    "site_visit['drop'] = site_visit['Page location'].apply(categorize_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "print(site_visit['Page location'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the id for site visit (scanned qr code, submitted the forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_visit['ID'] = site_visit['Page location'].str.extract(r'utm_id=(\\d+)')\n",
    "form_submit1['ID'] = form_submit1['Referrer'].str.extract(r'utm_id=(\\d+)')\n",
    "form_submit2['ID'] = form_submit2['Referrer'].str.extract(r'utm_id=(\\d+)')\n",
    "\n",
    "\n",
    "form_submit1['utm_id'].fillna(form_submit1['Referrer'].str.extract(r'utm_id=(\\d+)').iloc[:, 0].astype(float), inplace=True)\n",
    "\n",
    "form_submit2['utm_id'].fillna(form_submit2['Referrer'].str.extract(r'utm_id=(\\d+)').iloc[:, 0].astype(float), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking how many unique id are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(site_visit['ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract IDs from form_submit1 as a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16167', '39699', '03531', '18238', '26156', '44897', '24333', '31533']\n"
     ]
    }
   ],
   "source": [
    "# Extract IDs from form_submit1 as a list\n",
    "extracted_ids = form_submit1['utm_id'].tolist() + form_submit2['utm_id'].tolist()\n",
    "formatted_ids = [str(int(id)).zfill(5) if isinstance(id, (int, float)) else id for id in extracted_ids]\n",
    "\n",
    "\n",
    "# Create the 'submit_form' column in site_visit based on whether the ID is in both DataFrames\n",
    "site_visit['submit_form'] = site_visit['ID'].isin(formatted_ids)\n",
    "\n",
    "\n",
    "print(formatted_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking if they have scanned the qr code more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "03387    2\n",
      "26156    2\n",
      "42331    2\n",
      "39699    2\n",
      "35942    2\n",
      "        ..\n",
      "30737    1\n",
      "03531    1\n",
      "32624    1\n",
      "05869    1\n",
      "45145    1\n",
      "Name: count, Length: 77, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pivoted_df = pd.pivot_table(site_visit, columns='Event name', values='Sessions', index=['ID', 'Date', 'drop', 'submit_form'], aggfunc='first', fill_value=0)\n",
    "pivoted_df.reset_index(inplace=True)\n",
    "\n",
    "pivoted_df = pivoted_df.drop('Any_Form-Submit', axis=1)\n",
    "\n",
    "pivoted_df = pivoted_df[pivoted_df['ID']!='00000']\n",
    "\n",
    "# Count the number of occurrences of each ID\n",
    "id_counts = pivoted_df['ID'].value_counts()\n",
    "\n",
    "# Create the 'visit_again' column based on the ID counts\n",
    "pivoted_df['visit_again'] = pivoted_df['ID'].map(id_counts) > 1\n",
    "\n",
    "# Fill any NaN values with False (for IDs that only appear once)\n",
    "pivoted_df['visit_again'] = pivoted_df['visit_again'].fillna(False)\n",
    "\n",
    "pivoted_df['Date'] = pd.to_datetime(pivoted_df['Date'], format='%Y%m%d')\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "pivoted_df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Keep the earliest date records for duplicate IDs\n",
    "pivoted_df.drop_duplicates(subset='ID', keep='first', inplace=True)\n",
    "\n",
    "\n",
    "print(id_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join '手机号码' from form_submit1 to pivoted_df based on 'ID' with suffix '_form1'\n",
    "pivoted_df = pivoted_df.merge(form_submit1[['ID', '手机号码']], on='ID', how='left')\n",
    "\n",
    "# Left join '手机号码' from form_submit2 to pivoted_df based on 'ID' with suffix '_form2'\n",
    "pivoted_df = pivoted_df.merge(form_submit2[['ID', '手机号码']], on='ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import skip\n",
    "import phonenumbers\n",
    "\n",
    "\n",
    "sam_us = pd.read_csv(\"data/October-Target-SAM-List-US-All.csv\",usecols=['Snowball Map', 'Contact Phone','Business Phone','All Phone (Print Shop)'])\n",
    "sam_canada = pd.read_csv(\"data/October-Target-SAM-List-CAN-All.csv\",usecols=['Snowball Map', 'Contact Phone','Business Phone','All Phone (Print Shop)'])\n",
    "\n",
    "sam_list = pd.concat([sam_us, sam_canada], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine '手机号码' from both '手机号码' columns\n",
    "pivoted_df['Phone'] = pivoted_df['手机号码_x'].fillna(pivoted_df['手机号码_y'])\n",
    "\n",
    "# Drop the '手机号码_form1' and '手机号码_form2' columns\n",
    "pivoted_df.drop(['手机号码_x', '手机号码_y'], axis=1, inplace=True)\n",
    "\n",
    "pivoted_df['Phone'] = pivoted_df['Phone'].str.replace('-', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the call is empty, then fill the phone numbers from the form submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have loaded the 'pivoted_df' and 'sam_us' DataFrames\n",
    "pivoted_df['ID'] = pivoted_df['ID'].astype(np.int64)\n",
    "\n",
    "\n",
    "# Merge 'pivoted_df' and 'sam_us' based on 'ID' and 'Snowball Map'\n",
    "merged_df = pd.merge(pivoted_df, sam_list, left_on='ID', right_on='Snowball Map', how='left')\n",
    "\n",
    "# Define a function to fill 'Phone' column based on priority\n",
    "def fill_phone(row):\n",
    "    if not pd.isna(row['Contact Phone']):\n",
    "        return row['Contact Phone']\n",
    "    elif not pd.isna(row['Business Phone']):\n",
    "        return row['Business Phone']\n",
    "    elif not pd.isna(row['All Phone (Print Shop)']):\n",
    "        return row['All Phone (Print Shop)']\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the 'Phone' column in merged_df\n",
    "merged_df['Phone'] = merged_df.apply(fill_phone, axis=1)\n",
    "\n",
    "# Drop the unnecessary columns from 'sam_us' that were merged into 'merged_df'\n",
    "merged_df.drop(columns=['Snowball Map', 'Contact Phone', 'Business Phone', 'All Phone (Print Shop)'], inplace=True)\n",
    "\n",
    "# Now, merged_df contains the 'Phone' column filled based on your specified order.\n",
    "\n",
    "pivoted_df = merged_df.copy()\n",
    "\n",
    "pivoted_df['Phone'] = pivoted_df['Phone'].str.replace(r'\\D', '', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Inbound Call Tracker to match if they scanned and have called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound_call = pd.read_csv(\"data/Inbound-Call-Notes.csv\")\n",
    "\n",
    "# Add '2023' to the 'Date' column\n",
    "inbound_call['Date'] = '2023 ' + inbound_call['Date']\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "inbound_call['Date'] = pd.to_datetime(inbound_call['Date'], format='%Y %a %m/%d')\n",
    "\n",
    "# Filter rows for October (month == 10)\n",
    "october_calls = inbound_call[inbound_call['Date'].dt.month == 10]\n",
    "october_calls = october_calls.copy()  # Make a copy of the DataFrame\n",
    "october_calls['Date'] = pd.to_datetime(october_calls['Date'],format='%Y %a %m/%d').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "october_dm_calls = october_calls[october_calls['Extension Channel']== 'DM']\n",
    "\n",
    "extracted_phone = october_dm_calls['Phone'].tolist() \n",
    "pivoted_df['inbound_call'] = pivoted_df['Phone'].isin(extracted_phone)\n",
    "\n",
    "october_dm_calls = october_dm_calls.rename(columns={october_dm_calls.columns[16]: 'Campaign'})\n",
    "october_dm_calls['Campaign'].unique()\n",
    "\n",
    "october_ft_calls = october_dm_calls[october_dm_calls['Campaign']=='Mkt_DM_Snowflake_OctoberFreeTrial']\n",
    "\n",
    "df =october_ft_calls.copy()\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Define the date ranges for 'drop1' and 'drop2'\n",
    "start_date_drop1 = pd.to_datetime('2023-10-03')\n",
    "end_date_drop1 = pd.to_datetime('2023-10-05')\n",
    "start_date_drop2 = pd.to_datetime('2023-10-18')\n",
    "end_date_drop2 = pd.to_datetime('2023-10-20')\n",
    "\n",
    "# Create the 'Period' column based on date ranges\n",
    "df['Period'] = df.apply(lambda row: 'drop1' if start_date_drop1 <= row['Date'] <= end_date_drop1 else 'drop2', axis=1)\n",
    "# Get the column names except for the last one\n",
    "cols_except_last = df.columns[:-1].tolist()\n",
    "# Reorder the columns as desired\n",
    "new_order = ['Date', 'Period'] + cols_except_last\n",
    "df = df[new_order]\n",
    "\n",
    "# Create a new DataFrame with the desired column order\n",
    "df.to_csv(\"data/october_dm_called.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your existing DataFrame 'pivoted_df'\n",
    "\n",
    "# Define the data for the two new rows\n",
    "new_rows_data = [\n",
    "    {'ID': '31533','Date': '10/12/23', 'drop': 'drop1', 'submit_form': True, 'AnyFormSubmit': 1, 'click': 0, 'cta_click': 0, 'first_visit': 0, 'form_start': 0, 'page_view': 0, 'scroll': 0, 'session_start': 0, 'user_engagement': 0, 'visit_again': False, 'Phone': '7854919016', 'inbound_call': True},\n",
    "    {'ID': '18238','Date': '10/11/23', 'drop': 'drop1', 'submit_form': True, 'AnyFormSubmit': 1, 'click': 0, 'cta_click': 0, 'first_visit': 0, 'form_start': 0, 'page_view': 0, 'scroll': 0, 'session_start': 0, 'user_engagement': 0, 'visit_again': False, 'Phone': '201-523-6952', 'inbound_call': False}\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "new_rows_df = pd.DataFrame(new_rows_data)\n",
    "\n",
    "# Append the new rows to the 'pivoted_df' DataFrame\n",
    "pivoted_df = pd.concat([pivoted_df, new_rows_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# 'ignore_index=True' resets the index of the combined DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df.to_csv(\"data/clean_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
